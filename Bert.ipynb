{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Bert.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "ALhFVl5QSHxB",
        "HDB_4Ev9B4be",
        "YG-GbUQtBt_7",
        "9me3ENn5FUIt",
        "u6COAuPTEFEs",
        "VFa5Co5wH5rH"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ALhFVl5QSHxB",
        "colab_type": "text"
      },
      "source": [
        "##Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "39A8zQ4hAgJv",
        "colab_type": "code",
        "outputId": "91a7816e-8bf5-45b3-fe87-6c25f793fb0d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))\n",
        "\n",
        "import torch\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "n_gpu = torch.cuda.device_count()\n",
        "torch.cuda.get_device_name(0)\n",
        "\n",
        "from google.colab import files\n",
        "import pandas as pd\n",
        "from pytorch_pretrained_bert import BertTokenizer\n",
        "import nltk\n",
        "import re\n",
        "nltk.download('punkt')\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "from pytorch_pretrained_bert import BertModel, BertForMaskedLM\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "% matplotlib inline"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pAinP-1XAwxZ",
        "colab_type": "code",
        "outputId": "86f4f89a-2c46-4e69-8665-6c83f26f701f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 440
        }
      },
      "source": [
        "!pip install pytorch-pretrained-bert pytorch-nlp"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pytorch-pretrained-bert\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d7/e0/c08d5553b89973d9a240605b9c12404bcf8227590de62bae27acbcfe076b/pytorch_pretrained_bert-0.6.2-py3-none-any.whl (123kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 6.4MB/s \n",
            "\u001b[?25hCollecting pytorch-nlp\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4f/51/f0ee1efb75f7cc2e3065c5da1363d6be2eec79691b2821594f3f2329528c/pytorch_nlp-0.5.0-py3-none-any.whl (90kB)\n",
            "\u001b[K     |████████████████████████████████| 92kB 10.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (2019.12.20)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (1.18.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (2.21.0)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (1.12.38)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (4.38.0)\n",
            "Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (1.4.0)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (3.0.4)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (1.24.3)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (2.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (2020.4.5.1)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-pretrained-bert) (0.9.5)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-pretrained-bert) (0.3.3)\n",
            "Requirement already satisfied: botocore<1.16.0,>=1.15.38 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-pretrained-bert) (1.15.38)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.38->boto3->pytorch-pretrained-bert) (2.8.1)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.38->boto3->pytorch-pretrained-bert) (0.15.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.16.0,>=1.15.38->boto3->pytorch-pretrained-bert) (1.12.0)\n",
            "Installing collected packages: pytorch-pretrained-bert, pytorch-nlp\n",
            "Successfully installed pytorch-nlp-0.5.0 pytorch-pretrained-bert-0.6.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HDB_4Ev9B4be",
        "colab_type": "text"
      },
      "source": [
        "##Load data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3RTGiQRABBDj",
        "colab_type": "code",
        "outputId": "562d6667-93a6-4a96-b217-86955a5364d7",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 74
        }
      },
      "source": [
        "# Upload the train file from your local drive\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-c60d85f7-f795-49e0-a698-3e92388728b5\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-c60d85f7-f795-49e0-a698-3e92388728b5\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving all_files.txt to all_files.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g6YA0XMXB6lF",
        "colab_type": "code",
        "outputId": "efcbe090-4651-4d81-ff69-f85cf0539405",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "source": [
        "df = pd.read_csv(\"all_files.txt\", delimiter='\\n', header=None)\n",
        "df.sample(5)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>In the United States, the modern use of the te...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>I agree with you - Students do need to learn h...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>On the topic of the Native American languages,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>Sorry if youve heard it a million times before...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>Looking through the comments, I see a lot of p...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                    0\n",
              "17  In the United States, the modern use of the te...\n",
              "31  I agree with you - Students do need to learn h...\n",
              "9   On the topic of the Native American languages,...\n",
              "25  Sorry if youve heard it a million times before...\n",
              "14  Looking through the comments, I see a lot of p..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rKWxK4uyB1cF",
        "colab_type": "text"
      },
      "source": [
        "##Tokenization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wdlRx8moGXrX",
        "colab_type": "code",
        "outputId": "0c03d1ca-cf92-4b44-9543-559150fe9a5d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222
        }
      },
      "source": [
        "def getSentences(df):\n",
        "  max_length_sentence = 0\n",
        "  sentences = []\n",
        "  for key, value in df.iteritems(): \n",
        "      for i, e in enumerate(value):\n",
        "        sentence = nltk.tokenize.sent_tokenize(e)\n",
        "        max_length_sentence = max(max_length_sentence, len(sentence))\n",
        "        sentences = sentences + sentence\n",
        "  print(\"\\nSentence: \", sentences[0])\n",
        "  print(\"Number of sentences: \", len(sentences))\n",
        "  print(\"Maximum lenght of sentence:\", max_length_sentence)\n",
        "  return sentences\n",
        "\n",
        "def removeWikification(sentences):\n",
        "  newSentences = []\n",
        "  wikification = ['Wiki__','wiki__','wiki_','Wiki_','wiki','Wiki']\n",
        "  \n",
        "  for sentence in sentences:\n",
        "    new_str = sentence.lower()\n",
        "    tokens = new_str.split()\n",
        "    wiki_words =[]\n",
        "\n",
        "    # Find the wiki words\n",
        "    for token in tokens:\n",
        "        if token.find('wiki') == 0:\n",
        "            wiki_words.append(token)\n",
        "    \n",
        "    # Get wikification\n",
        "    for word in wiki_words:\n",
        "      wikification.append('__'+(word.rsplit('_', 1))[1])\n",
        "    \n",
        "    # Remove wikification\n",
        "    for string in wikification:\n",
        "      sentence = sentence.replace(string,'')\n",
        "    \n",
        "    newSentences.append(sentence)\n",
        "    \n",
        "  res2 = [sub.replace('___', ' ') for sub in newSentences]\n",
        "  res1 = [sub.replace('__', ' ') for sub in res2]\n",
        "  res = [sub.replace('_', ' ') for sub in res1]\n",
        "  print(\"\\nNo wiki sentence: \", res[0])\n",
        "  \n",
        "  return res\n",
        "\n",
        "sentences = getSentences(df)\n",
        "sentences_without_wiki = removeWikification(sentences)\n",
        "sentences_sep = [\"[CLS] \" + sentence + \" [SEP]\" for sentence in sentences_without_wiki]\n",
        "print(\"\\nSentence with sep: \", sentences_sep[0])\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
        "tokenized_texts = [tokenizer.tokenize(sentence) for sentence in sentences_sep]\n",
        "print (\"\\nTokenized sentence:\", tokenized_texts[0])\n",
        "print(\"Number of tokens for first sentence:\", len(tokenized_texts[0]))"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Sentence:  I am also currently seeking my degree from said institution and I am shocked and awed everyday by the mindlessness of the students.\n",
            "Number of sentences:  909\n",
            "Maximum lenght of sentence: 93\n",
            "\n",
            "No wiki sentence:  I am also currently seeking my degree from said institution and I am shocked and awed everyday by the mindlessness of the students.\n",
            "\n",
            "Sentence with sep:  [CLS] I am also currently seeking my degree from said institution and I am shocked and awed everyday by the mindlessness of the students. [SEP]\n",
            "\n",
            "Tokenized sentence: ['[CLS]', 'i', 'am', 'also', 'currently', 'seeking', 'my', 'degree', 'from', 'said', 'institution', 'and', 'i', 'am', 'shocked', 'and', 'awe', '##d', 'everyday', 'by', 'the', 'mind', '##lessness', 'of', 'the', 'students', '.', '[SEP]']\n",
            "Number of tokens for first sentence: 28\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LRqoZxihKfg0",
        "colab_type": "code",
        "outputId": "fdd65637-594d-4bb5-a69f-9e41310284e3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        }
      },
      "source": [
        "# Set the maximum sequence length. The longest sequence in our training set is 93, but we'll leave room on the end anyway. \n",
        "# In the original paper, the authors used a length of 512.\n",
        "MAX_LEN = 128\n",
        "\n",
        "# Use the BERT tokenizer to convert the tokens to their index numbers in the BERT vocabulary\n",
        "indexed_tokens = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\n",
        "\n",
        "# Display the words with their indeces for the first sentence.\n",
        "for tup in zip(tokenized_texts[0], indexed_tokens[0]):\n",
        "    print('{:<12} {:>6,}'.format(tup[0], tup[1]))\n",
        "\n",
        "# Pad our input tokens\n",
        "input_ids = pad_sequences(indexed_tokens, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[CLS]           101\n",
            "i             1,045\n",
            "am            2,572\n",
            "also          2,036\n",
            "currently     2,747\n",
            "seeking       6,224\n",
            "my            2,026\n",
            "degree        3,014\n",
            "from          2,013\n",
            "said          2,056\n",
            "institution   5,145\n",
            "and           1,998\n",
            "i             1,045\n",
            "am            2,572\n",
            "shocked       7,135\n",
            "and           1,998\n",
            "awe          15,180\n",
            "##d           2,094\n",
            "everyday     10,126\n",
            "by            2,011\n",
            "the           1,996\n",
            "mind          2,568\n",
            "##lessness   24,913\n",
            "of            1,997\n",
            "the           1,996\n",
            "students      2,493\n",
            ".             1,012\n",
            "[SEP]           102\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YG-GbUQtBt_7",
        "colab_type": "text"
      },
      "source": [
        "##Segment ID"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ELUWcDDv54kw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9f72d6a3-0cfb-4161-f10b-073afddf8fcd"
      },
      "source": [
        "#BERT expects sentence pairs, 1 and 0s to distinguish. We have single-sentence \n",
        "#inputs so it requires a serie of 1s\n",
        "\n",
        "# Mark each of the tokens as belonging to sentence \"1\".\n",
        "segments_ids = [[1] * len(text) for text in tokenized_texts]\n",
        "\n",
        "print (len(segments_ids[0]))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "28\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3KuhGNxCB_X5",
        "colab_type": "text"
      },
      "source": [
        "##Extracting embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9me3ENn5FUIt",
        "colab_type": "text"
      },
      "source": [
        "###Running BERT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_zQ7tOvRCGU1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# We need to convert our data to torch tensors and call the BERT model\n",
        "\n",
        "# Convert inputs to PyTorch tensors\n",
        "tokens_tensors = [torch.tensor([tokens]) for tokens in indexed_tokens]\n",
        "segments_tensors = [torch.tensor([segment]) for segment in segments_ids]\n",
        "\n",
        "# Load pre-trained model (weights)\n",
        "model = BertModel.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# Put the model in \"evaluation\" mode, meaning feed-forward operation.\n",
        "# Evaluation mode turns off dropout regularization which is used in training\n",
        "model.eval()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xnAQVIFGDNhK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "bcaceaa2-7be5-46e6-8604-74c1f361f7e5"
      },
      "source": [
        "# Let’s fetch the hidden states of the network\n",
        "# Deactivates the gradient calculations, saves memory, and speeds up computation\n",
        "# Predict hidden states features for each layer\n",
        "encoded_layers = [None] * len(tokens_tensors)\n",
        "print(len(tokens_tensors))\n",
        "i = 0\n",
        "for tokens_tensor, segments_tensor in zip(tokens_tensors, segments_tensors):\n",
        "  with torch.no_grad():\n",
        "      encoded_layers[i], _ = model(tokens_tensor, segments_tensor)\n",
        "  i += 1"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "909\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u6COAuPTEFEs",
        "colab_type": "text"
      },
      "source": [
        "###Understanding the output"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FGpB67_oEHgs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "4de90b29-a5e8-496a-d650-90c78d667cd0"
      },
      "source": [
        "# One object of encoded_layers has four dimensions:\n",
        "# The layer number\n",
        "# The batch number\n",
        "# The word / token number in one sentence\n",
        "# The hidden unit / feature number\n",
        "\n",
        "# For the first sentence:\n",
        "print (\"Number of layers:\", len(encoded_layers[0]))\n",
        "layer_i = 0\n",
        "\n",
        "print (\"Number of batches:\", len(encoded_layers[0][layer_i]))\n",
        "batch_i = 0\n",
        "\n",
        "print (\"Number of tokens:\", len(encoded_layers[0][layer_i][batch_i]))\n",
        "token_i = 0\n",
        "\n",
        "print (\"Number of hidden units:\", len(encoded_layers[0][layer_i][batch_i][token_i]))"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of layers: 12\n",
            "Number of batches: 1\n",
            "Number of tokens: 28\n",
            "Number of hidden units: 768\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_UNeTobSFKsz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        },
        "outputId": "5103b8b1-f97b-4d49-c5b4-c955073a65f5"
      },
      "source": [
        "# Range of values for a given layer and token\n",
        "# For the 5th token in our sentence, select its feature values from layer 5.\n",
        "token_i = 5\n",
        "layer_i = 5\n",
        "vec = encoded_layers[0][layer_i][batch_i][token_i]\n",
        "\n",
        "# Plot the values as a histogram to show their distribution.\n",
        "plt.figure(figsize=(5,5))\n",
        "plt.hist(vec, bins=200)\n",
        "plt.show()"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 360x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rL-hiLRsF0HP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "49e28900-1c17-4037-bf4b-5d81b3bf0973"
      },
      "source": [
        "# Grouping the values by layer makes sense for the model,\n",
        "# but for our purposes we want it grouped by token\n",
        "\n",
        "# Current dimensions: [# layers, # batches, # tokens, # features]\n",
        "# Desired dimensions: [# tokens, # layers, # features]\n",
        "\n",
        "# BUT `encoded_layers objects` are Python lists.\n",
        "print('Type of encoded_layers: ', type(encoded_layers[0]))\n",
        "\n",
        "# Each layer in the list object is a torch tensor. (28 for first sentence)\n",
        "print('Tensor shape for each layer: ', encoded_layers[0][0].size())"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Type of encoded_layers:  <class 'list'>\n",
            "Tensor shape for each layer:  torch.Size([1, 28, 768])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RnuP7lTQGZCp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "47f29b8e-8b3d-44e1-9ffc-bd241b3fc636"
      },
      "source": [
        "# Let's reshape\n",
        "\n",
        "# Concatenate the tensors for all layers. We use `stack` here to\n",
        "# create a new dimension in the tensor\n",
        "\n",
        "token_embeddings = [torch.stack(encoded_layer, dim=0) for encoded_layer in encoded_layers]\n",
        "print('Layers concatenated:', token_embeddings[0].size())\n",
        "\n",
        "# Let’s get rid of the “batches” dimension since we don’t need it\n",
        "# Remove dimension 1, the \"batches\"\n",
        "\n",
        "token_embeddings = [torch.squeeze(token_embedding, dim=1) for token_embedding in token_embeddings]\n",
        "print('Batches removed:', token_embeddings[0].size())\n",
        "\n",
        "# Finally, we can switch around the “layers” and “tokens” dimensions\n",
        "# Swap dimensions 0 and 1\n",
        "\n",
        "token_embeddings = [token_embedding.permute(1,0,2) for token_embedding in token_embeddings]\n",
        "print('Dimensions switched:', token_embeddings[0].size())"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Layers concatenated: torch.Size([12, 1, 28, 768])\n",
            "Batches removed: torch.Size([12, 28, 768])\n",
            "Dimensions switched: torch.Size([28, 12, 768])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VFa5Co5wH5rH",
        "colab_type": "text"
      },
      "source": [
        "###Creating word vectors from hidden states"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R7qWdbzfH-xD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "71579fbf-1b34-45c0-bbbb-e24424486863"
      },
      "source": [
        "# We want individual word vector but have 12 vectors (layers) for each token\n",
        "# We need to combine those vetors\n",
        "# Different combinations give different results depending on the application\n",
        "# Let's choose concatenate last four hidden layers for now\n",
        "\n",
        "\n",
        "# `token_embeddings` objects are [nb of tokens x 12 x 768] tensors\n",
        "all_vectors = []\n",
        "\n",
        "# For each sentence\n",
        "for token_embedding in token_embeddings:\n",
        "  # Stores the token vectors, with shape [nb of tokens x 3,072]\n",
        "  token_vectors = []\n",
        "\n",
        "  # For each token in the sentence\n",
        "  for token in token_embedding:\n",
        "      # `token` is a [12 x 768] tensor\n",
        "      # Concatenate the vectors (that is, append them together) from the last \n",
        "      # 4 layers. Each layer vector is 768 values, so `concat_vector` is length 3,072.\n",
        "      concat_vector = torch.cat((token[-1], token[-2], token[-3], token[-4]), dim=0)\n",
        "      \n",
        "      # Use `concat_vector` to represent `token`.\n",
        "      token_vectors.append(concat_vector)\n",
        "    \n",
        "  all_vectors.append(token_vectors)\n",
        "\n",
        "print ('Shape for 1st sentence is: %d x %d' % (len(all_vectors[0]), len(all_vectors[0][0])))\n",
        "print('For the 1st sentence, 1st token \\'', tokenized_texts[0][0],'\\' has vector', all_vectors[0][0])\n",
        "print('For the 1st sentence, 2st token \\'', tokenized_texts[0][1],'\\' has vector', all_vectors[0][1])"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape for 1st sentence is: 28 x 3072\n",
            "For the 1st sentence, 1st token ' [CLS] ' has vector tensor([ 0.2291,  0.2853,  0.0739,  ..., -0.0238,  1.0367, -0.1663])\n",
            "For the 1st sentence, 2st token ' i ' has vector tensor([ 0.5938, -0.3589,  0.2258,  ...,  0.1611,  0.7861, -0.0907])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MlYygun2LSIv",
        "colab_type": "text"
      },
      "source": [
        "###Confirming contextually dependant vectors\n",
        "-> Need bank/bank example"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PRPAPMEbJN4i",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "\n",
        "Code from [BERT Word Embeddings Tutorial by Chris McCormick and Nick Ryan](http://mccormickml.com/2019/05/14/BERT-word-embeddings-tutorial/#1-loading-pre-trained-bert) "
      ]
    }
  ]
}